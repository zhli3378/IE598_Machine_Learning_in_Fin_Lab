{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zhenlong Li (zl51)\n",
    "## IE598 MLF F18\n",
    "### Module 6 Homework (Cross validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Iris dataset, with 90% for training and 10% for test and the decision tree model that you submitted for Module 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, [2, 3]]\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Random test train splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run in-sample and out-of-sample accuracy for 10 different samples by changing random_state from 1 to 10 in sequence. \n",
    "Display the individual scores, calculate the mean and standard deviation of the set.  Report in a table format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random state = 1  Accuracy score of in-sample: 0.985 Accuracy score of out-of-sample: 0.933\n",
      "random state = 2  Accuracy score of in-sample: 0.985 Accuracy score of out-of-sample: 1.000\n",
      "random state = 3  Accuracy score of in-sample: 0.985 Accuracy score of out-of-sample: 0.867\n",
      "random state = 4  Accuracy score of in-sample: 0.985 Accuracy score of out-of-sample: 1.000\n",
      "random state = 5  Accuracy score of in-sample: 0.985 Accuracy score of out-of-sample: 1.000\n",
      "random state = 6  Accuracy score of in-sample: 0.985 Accuracy score of out-of-sample: 0.867\n",
      "random state = 7  Accuracy score of in-sample: 0.985 Accuracy score of out-of-sample: 0.933\n",
      "random state = 8  Accuracy score of in-sample: 0.985 Accuracy score of out-of-sample: 1.000\n",
      "random state = 9  Accuracy score of in-sample: 0.985 Accuracy score of out-of-sample: 0.933\n",
      "random state = 10  Accuracy score of in-sample: 0.985 Accuracy score of out-of-sample: 1.000\n",
      "in-sample mean: 0.985 standard deviation: 0.000\n",
      "out-of-sample mean  0.953 standard deviation 0.052\n"
     ]
    }
   ],
   "source": [
    "rs_range = [1,2,3,4,5,6,7,8,9,10]\n",
    "insample_scores = []\n",
    "outofsample_scores = []\n",
    "\n",
    "for i in rs_range:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=i, stratify=y)\n",
    "    tree = DecisionTreeClassifier(criterion='gini',\n",
    "                                  max_depth=4,\n",
    "                                  random_state=1)\n",
    "    tree.fit(X_train, y_train)\n",
    "    y_train_pred = tree.predict(X_train)\n",
    "    y_pred = tree.predict(X_test)\n",
    "    insample_scores.append(metrics.accuracy_score(y_train, y_train_pred))\n",
    "    outofsample_scores.append(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "j = 1\n",
    "while j < len(rs_range)+1:\n",
    "    print(\"random state =\", j, \"\",\n",
    "          'Accuracy score of in-sample: %.3f' % insample_scores[j-1],\n",
    "          'Accuracy score of out-of-sample: %.3f' % outofsample_scores[j-1])\n",
    "    j += 1   \n",
    "\n",
    "print(\"in-sample mean: %.3f\" % np.mean(insample_scores),\n",
    "      \"standard deviation: %.3f\" % np.std(insample_scores))\n",
    "print(\"out-of-sample mean  %.3f\" % np.mean(outofsample_scores),\n",
    "      \"standard deviation %.3f\" % np.std(outofsample_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://github.com/zhli3378/IE598_Machine_Learning_in_Fin_Lab/blob/master/IE598_F18_HW6/Part1.png?raw=true\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://github.com/zhli3378/IE598_Machine_Learning_in_Fin_Lab/blob/master/IE598_F18_HW6/Part1.png?raw=true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now rerun your model using cross_val_scores with k-fold CV (k=10).  \n",
    "Report the individual fold accuracy scores, the mean CV score and the standard deviation of the folds.  Now run the out-of-sample accuracy score.  Report in a table format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mathod 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:  1, Acc: 1.000\n",
      "Fold:  2, Acc: 0.933\n",
      "Fold:  3, Acc: 1.000\n",
      "Fold:  4, Acc: 0.933\n",
      "Fold:  5, Acc: 0.933\n",
      "Fold:  6, Acc: 0.917\n",
      "Fold:  7, Acc: 1.000\n",
      "Fold:  8, Acc: 0.833\n",
      "Fold:  9, Acc: 1.000\n",
      "Fold: 10, Acc: 0.917\n",
      "\n",
      "CV accuracy: 0.947 +/- 0.052\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=10, random_state=1).split(X_train, y_train)\n",
    "scores = []\n",
    "for k, (train, test) in enumerate(kfold):\n",
    "    tree.fit(X_train[train], y_train[train])\n",
    "    score = tree.score(X_train[test], y_train[test])\n",
    "    scores.append(score)\n",
    "    print('Fold: %2d, Acc: %.3f' % (k+1, score))\n",
    "    \n",
    "print('\\nCV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy scores: [1.         0.93333333 1.         0.93333333 0.93333333 0.91666667\n",
      " 1.         0.83333333 1.         0.91666667]\n",
      "CV accuracy: 0.947 +/- 0.052\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(estimator=tree, X=X_train, y=y_train, cv=10, n_jobs=1)\n",
    "\n",
    "print('CV accuracy scores: %s' % scores)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-of-sample accuracy：0.933\n"
     ]
    }
   ],
   "source": [
    "print('Out-of-sample accuracy：%.3f' % outofsample_scores[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://github.com/zhli3378/IE598_Machine_Learning_in_Fin_Lab/blob/master/IE598_F18_HW6/Part2.png?raw=true\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://github.com/zhli3378/IE598_Machine_Learning_in_Fin_Lab/blob/master/IE598_F18_HW6/Part2.png?raw=true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is Zhenlong Li\n",
      "My NetID is: zl51\n",
      "I hereby certify that I have read the University policy on Academic Integrity and that I am not in violation.\n"
     ]
    }
   ],
   "source": [
    "print(\"My name is Zhenlong Li\")\n",
    "print(\"My NetID is: zl51\")\n",
    "print(\"I hereby certify that I have read the University policy on Academic Integrity and that I am not in violation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a short paragraph summarizing your findings.  Which method of measuring accuracy provides the best estimate of how a model will do against unseen data?  Which one is more efficient to run?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From what I found, I think K-fold can provide better estimate of how a model will do against unseen data since it can do multiple calculations by spliting the data into different test sizes. As for the efficiency, it's easier to compute by using random train test split since it doed not need too many calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to github repo: https://github.com/zhli3378/IE598_Machine_Learning_in_Fin_Lab/blob/master/IE598_F18_HW6/IE598_F18_HW6.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
